{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices: Advanced Regression Techniques\n",
    "\n",
    "Predict sales prices and practice feature engineering, RFs, and gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./train.csv', sep=',')\n",
    "df_test = pd.read_csv('./test.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration/Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df_train.isnull().sum().sort_values(ascending=False)\n",
    "percent_1 = df_train.isnull().sum()/df_train.isnull().count()*100\n",
    "percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the null values using HeatMaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_train.isnull(), yticklabels=False, cbar=False, cmap='Blues')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation heatmap of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_heatmap(df):\n",
    "    _ , ax = plt.subplots(figsize =(7, 5))\n",
    "    colormap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    \n",
    "    _ = sns.heatmap(\n",
    "        df.corr(), \n",
    "        cmap = colormap,\n",
    "        square=True, \n",
    "        cbar_kws={'shrink':.9}, \n",
    "        ax=ax,\n",
    "        annot=True, \n",
    "        linewidths=0.1,vmax=1.0, linecolor='white',\n",
    "        annot_kws={'fontsize':12}\n",
    "    )\n",
    "    \n",
    "    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "#correlation_heatmap(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies the average where the values are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appty_mean(df):\n",
    "    columns = df.select_dtypes(exclude=[object]).columns\n",
    "    for c in columns:\n",
    "        index = df[df[c].isnull()].index\n",
    "        df.loc[index, c] = np.mean(df[c])\n",
    "    return df\n",
    "\n",
    "df_train = appty_mean(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies the mode where the values are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appty_mode(df):\n",
    "    columns = df.select_dtypes(['object']).columns\n",
    "    for c in columns:\n",
    "        mode = df[c].mode().values\n",
    "        index = df[df[c].isnull()].index\n",
    "        df.loc[index, c] = mode\n",
    "    return df\n",
    "\n",
    "df_train = appty_mode(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the null values using HeatMaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_train.isnull(), yticklabels=False, cbar=False, cmap='Blues')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the remaining rows with null values in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with categorical column, using LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorial_columns(df):\n",
    "    columns = df.select_dtypes(['object']).columns\n",
    "    for c in columns:\n",
    "        le = LabelEncoder()\n",
    "        label = le.fit_transform(df[c])\n",
    "        df.loc[:, c] = label\n",
    "    return df\n",
    "\n",
    "df_train = to_categorial_columns(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.log(df_train['SalePrice'])\n",
    "df_train = df_train.drop(columns=['Id', 'SalePrice'])\n",
    "x_train = df_train.values\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = appty_mean(df_test)\n",
    "\n",
    "df_test = appty_mode(df_test)\n",
    "\n",
    "df_test = to_categorial_columns(df_test)\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = df_test['Id'].values\n",
    "Id = Id.astype(int)\n",
    "df_test = df_test.drop(columns=['Id'])\n",
    "x_test = scaler.transform(df_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste inicial de uma modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = x_train, y_train\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "lasso = Lasso()\n",
    "xgbr = XGBRegressor()\n",
    "gbr = GradientBoostingRegressor()\n",
    "svr_linear = SVR(kernel='linear')\n",
    "knnR = KNeighborsRegressor(n_neighbors=20, n_jobs=-1)\n",
    "rf = RandomForestRegressor(n_estimators=900,  random_state=RANDOM_SEED)\n",
    "svr_rbf = SVR(kernel= 'rbf', gamma= 'auto', tol=0.001, C=100.0, max_iter=-1)\n",
    "et  = ExtraTreesRegressor(n_estimators=950 , max_features='auto', max_leaf_nodes=None,\n",
    "                          n_jobs=-1, random_state=0, verbose=0)\n",
    "lr = LinearRegression(fit_intercept=True, normalize=True, copy_X=True, n_jobs=-1)\n",
    "#reg = StackingCVRegressor(regressors=[xgbr , gbr, lr, et],\n",
    "#                          random_state=RANDOM_SEED,\n",
    "#                          meta_regressor=lr)\n",
    "reg = StackingCVRegressor(regressors=(svr, lasso, rf),\n",
    "                          random_state=RANDOM_SEED,\n",
    "                          meta_regressor=lasso)\n",
    "\n",
    "alg = zip([lasso, gbr, svr_linear, knnR, rf, svr_rbf, et, reg],\n",
    "          ['Lasso', 'GBR', 'SVM Linear', 'KNN', 'RF', 'SVM RBF', 'ET', 'Stack'])\n",
    "\n",
    "print('5-fold cross validation scores:\\n')\n",
    "for clf, label in alg:\n",
    "    scores = cross_val_score(clf, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    print('Neg. MSE Score: {:.5f} (+/- {:.5f}) [{}]'.format(scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\n",
    "#model.fit(x_train, y_train)\n",
    "y_pred = reg.predict(x_test)\n",
    "y_pred = np.exp(y_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the predictions to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = dict(Id=Id, SalePrice=y_pred)\n",
    "df = pd.DataFrame(dict_).reset_index()\n",
    "df = df.drop('index', axis=1)\n",
    "\n",
    "df.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
